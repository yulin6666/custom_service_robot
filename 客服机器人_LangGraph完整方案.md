# åŸºäºLangGraphçš„æ™ºèƒ½å®¢æœæœºå™¨äººå®Œæ•´æ–¹æ¡ˆ

## ä¸€ã€é¡¹ç›®æ¦‚è¿°

### 1.1 é¡¹ç›®ç›®æ ‡
æ„å»ºä¸€ä¸ªåŸºäºLangGraphçš„æ™ºèƒ½å®¢æœæœºå™¨äººç³»ç»Ÿï¼Œæ”¯æŒå¤šè½®å¯¹è¯ã€æ„å›¾è¯†åˆ«ã€çŸ¥è¯†åº“æ£€ç´¢ã€ä»»åŠ¡æ‰§è¡Œã€äººå·¥è½¬æ¥ç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚

### 1.2 æ ¸å¿ƒç‰¹æ€§
- ğŸ¤– æ™ºèƒ½æ„å›¾è¯†åˆ«ä¸åˆ†ç±»
- ğŸ’¬ å¤šè½®å¯¹è¯ç®¡ç†
- ğŸ“š çŸ¥è¯†åº“æ£€ç´¢(RAG)
- ğŸ”§ ä»»åŠ¡æ‰§è¡Œä¸å·¥å…·è°ƒç”¨
- ğŸ‘¤ äººå·¥å®¢æœè½¬æ¥
- ğŸ“Š å¯¹è¯å†å²è®°å½•
- ğŸ”„ ä¼šè¯çŠ¶æ€ç®¡ç†
- ğŸ“ˆ æ•°æ®åˆ†æä¸ç›‘æ§

---

## äºŒã€ç³»ç»Ÿæ¶æ„è®¾è®¡

### 2.1 æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ç”¨æˆ·æ¥å£å±‚                              â”‚
â”‚  (Webç•Œé¢ / å¾®ä¿¡ / é’‰é’‰ / API / ç§»åŠ¨App)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    APIç½‘å…³ / è·¯ç”±å±‚                           â”‚
â”‚            (FastAPI / Flask / Django)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  LangGraphæ ¸å¿ƒå¼•æ“                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              çŠ¶æ€æœºæµç¨‹æ§åˆ¶                            â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚ æ„å›¾è¯†åˆ«â”‚â†’â”‚ è·¯ç”±åˆ†å‘â”‚â†’â”‚ ä»»åŠ¡æ‰§è¡Œâ”‚â†’â”‚ å“åº”ç”Ÿæˆâ”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚               â”‚               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLMæœåŠ¡å±‚   â”‚ â”‚ çŸ¥è¯†åº“å±‚   â”‚ â”‚  å·¥å…·/APIå±‚   â”‚
â”‚ OpenAI/æœ¬åœ°  â”‚ â”‚ VectorDB  â”‚ â”‚  è®¢å•/æ”¯ä»˜ç­‰  â”‚
â”‚  ChatGLMç­‰   â”‚ â”‚ PostgreSQLâ”‚ â”‚  å¤–éƒ¨ç³»ç»Ÿ     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚               â”‚               â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ•°æ®æŒä¹…å±‚                                 â”‚
â”‚     (Redisç¼“å­˜ / PostgreSQL / MongoDB)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æŠ€æœ¯æ ˆé€‰å‹

#### åç«¯æ ¸å¿ƒ
- **LangGraph**: çŠ¶æ€æœºå’Œå·¥ä½œæµç®¡ç†
- **LangChain**: LLMäº¤äº’å’Œå·¥å…·è°ƒç”¨
- **FastAPI**: WebæœåŠ¡æ¡†æ¶
- **Python 3.10+**: å¼€å‘è¯­è¨€

#### æ•°æ®å­˜å‚¨
- **PostgreSQL + pgvector**: å…³ç³»æ•°æ®å’Œå‘é‡å­˜å‚¨
- **Redis**: ä¼šè¯ç¼“å­˜å’Œæ¶ˆæ¯é˜Ÿåˆ—
- **Milvus/Qdrant**: å¯é€‰çš„ä¸“ç”¨å‘é‡æ•°æ®åº“

#### LLMæœåŠ¡
- **OpenAI GPT-4/GPT-3.5**: ä¸»åŠ›æ¨¡å‹
- **æœ¬åœ°æ¨¡å‹**: ChatGLM3ã€Qwenç­‰(å¯é€‰)
- **Embedding**: text-embedding-ada-002 / bge-large-zh

#### å‰ç«¯
- **React + TypeScript**: Webç•Œé¢
- **WebSocket**: å®æ—¶æ¶ˆæ¯æ¨é€
- **Ant Design / Material-UI**: UIç»„ä»¶åº“

#### éƒ¨ç½²è¿ç»´
- **Docker + Docker Compose**: å®¹å™¨åŒ–
- **Kubernetes**: ç”Ÿäº§ç¯å¢ƒç¼–æ’(å¯é€‰)
- **Nginx**: åå‘ä»£ç†
- **Prometheus + Grafana**: ç›‘æ§

---

## ä¸‰ã€LangGraphçŠ¶æ€æœºè®¾è®¡

### 3.1 çŠ¶æ€å®šä¹‰

```python
from typing import TypedDict, Annotated, Sequence
from langchain_core.messages import BaseMessage
import operator

class CustomerServiceState(TypedDict):
    """å®¢æœå¯¹è¯çŠ¶æ€"""
    # æ¶ˆæ¯å†å²
    messages: Annotated[Sequence[BaseMessage], operator.add]

    # ä¼šè¯ä¿¡æ¯
    session_id: str
    user_id: str

    # æ„å›¾è¯†åˆ«
    intent: str  # é—®å€™/å’¨è¯¢/æŠ•è¯‰/è®¢å•/å”®å/é—²èŠ/è½¬äººå·¥
    intent_confidence: float

    # ä¸Šä¸‹æ–‡ä¿¡æ¯
    current_topic: str
    entities: dict  # æå–çš„å®ä½“(è®¢å•å·ã€äº§å“åç­‰)

    # çŸ¥è¯†åº“æ£€ç´¢
    retrieved_docs: list

    # ä»»åŠ¡æ‰§è¡Œ
    need_tool_call: bool
    tool_results: dict

    # äººå·¥è½¬æ¥
    need_human: bool
    human_reason: str

    # å“åº”ç”Ÿæˆ
    final_response: str

    # æµç¨‹æ§åˆ¶
    next_step: str
    loop_count: int  # é˜²æ­¢æ­»å¾ªç¯
```

### 3.2 æ ¸å¿ƒèŠ‚ç‚¹å®šä¹‰

#### èŠ‚ç‚¹1: æ„å›¾è¯†åˆ«èŠ‚ç‚¹
```python
async def intent_recognition_node(state: CustomerServiceState) -> CustomerServiceState:
    """
    è¯†åˆ«ç”¨æˆ·æ„å›¾
    - é—®å€™: greeting
    - äº§å“å’¨è¯¢: product_inquiry
    - è®¢å•æŸ¥è¯¢: order_query
    - å”®åæœåŠ¡: after_sales
    - æŠ•è¯‰å»ºè®®: complaint
    - è½¬äººå·¥: transfer_human
    - é—²èŠ: chitchat
    """
    messages = state["messages"]
    last_message = messages[-1].content

    # ä½¿ç”¨LLMè¿›è¡Œæ„å›¾åˆ†ç±»
    intent_prompt = f"""
    åˆ†æä»¥ä¸‹ç”¨æˆ·æ¶ˆæ¯çš„æ„å›¾ï¼Œè¿”å›JSONæ ¼å¼ï¼š
    {{"intent": "æ„å›¾ç±»å‹", "confidence": 0.95, "entities": {{}}}}

    ç”¨æˆ·æ¶ˆæ¯ï¼š{last_message}
    """

    # è°ƒç”¨LLM
    result = await llm_client.classify_intent(intent_prompt)

    state["intent"] = result["intent"]
    state["intent_confidence"] = result["confidence"]
    state["entities"] = result["entities"]

    return state
```

#### èŠ‚ç‚¹2: è·¯ç”±åˆ†å‘èŠ‚ç‚¹
```python
def router_node(state: CustomerServiceState) -> str:
    """
    æ ¹æ®æ„å›¾è·¯ç”±åˆ°ä¸åŒå¤„ç†èŠ‚ç‚¹
    """
    intent = state["intent"]
    confidence = state["intent_confidence"]

    # ä½ç½®ä¿¡åº¦æˆ–æ˜ç¡®è¦æ±‚è½¬äººå·¥
    if confidence < 0.6 or intent == "transfer_human":
        return "transfer_to_human"

    # æ ¹æ®æ„å›¾è·¯ç”±
    intent_routes = {
        "greeting": "greeting_handler",
        "product_inquiry": "knowledge_retrieval",
        "order_query": "order_tool",
        "after_sales": "after_sales_handler",
        "complaint": "complaint_handler",
        "chitchat": "chitchat_handler"
    }

    return intent_routes.get(intent, "fallback_handler")
```

#### èŠ‚ç‚¹3: çŸ¥è¯†åº“æ£€ç´¢èŠ‚ç‚¹
```python
async def knowledge_retrieval_node(state: CustomerServiceState) -> CustomerServiceState:
    """
    ä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³ä¿¡æ¯(RAG)
    """
    messages = state["messages"]
    query = messages[-1].content

    # å‘é‡æ£€ç´¢
    retriever = get_vector_store_retriever()
    docs = await retriever.aretrieve(
        query=query,
        k=5,
        filter={"category": state.get("current_topic")}
    )

    state["retrieved_docs"] = docs
    state["next_step"] = "response_generation"

    return state
```

#### èŠ‚ç‚¹4: å·¥å…·è°ƒç”¨èŠ‚ç‚¹
```python
async def tool_execution_node(state: CustomerServiceState) -> CustomerServiceState:
    """
    æ‰§è¡Œå·¥å…·è°ƒç”¨(æŸ¥è¯¢è®¢å•ã€æ”¯ä»˜ç­‰)
    """
    intent = state["intent"]
    entities = state["entities"]

    if intent == "order_query":
        order_id = entities.get("order_id")
        if order_id:
            order_info = await query_order_api(order_id)
            state["tool_results"] = {"order": order_info}
        else:
            state["need_human"] = True
            state["human_reason"] = "ç¼ºå°‘è®¢å•å·ä¿¡æ¯"

    state["next_step"] = "response_generation"
    return state
```

#### èŠ‚ç‚¹5: å“åº”ç”ŸæˆèŠ‚ç‚¹
```python
async def response_generation_node(state: CustomerServiceState) -> CustomerServiceState:
    """
    ç”Ÿæˆæœ€ç»ˆå“åº”
    """
    messages = state["messages"]
    retrieved_docs = state.get("retrieved_docs", [])
    tool_results = state.get("tool_results", {})

    # æ„å»ºä¸Šä¸‹æ–‡
    context = ""
    if retrieved_docs:
        context += "ç›¸å…³çŸ¥è¯†ï¼š\n" + "\n".join([doc.page_content for doc in retrieved_docs])

    if tool_results:
        context += f"\næŸ¥è¯¢ç»“æœï¼š\n{json.dumps(tool_results, ensure_ascii=False)}"

    # ç”Ÿæˆå“åº”
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®¢æœåŠ©æ‰‹ï¼Œæ ¹æ®ä»¥ä¸‹ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ï¼š

    å¯¹è¯å†å²ï¼š
    {format_messages(messages)}

    å‚è€ƒä¿¡æ¯ï¼š
    {context}

    è¦æ±‚ï¼š
    - è¯­æ°”å‹å¥½ä¸“ä¸š
    - å›ç­”å‡†ç¡®ç®€æ´
    - å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œç¤¼è²Œåœ°è¯·æ±‚è¡¥å……
    """

    response = await llm_client.generate(prompt)
    state["final_response"] = response
    state["next_step"] = "end"

    return state
```

#### èŠ‚ç‚¹6: äººå·¥è½¬æ¥èŠ‚ç‚¹
```python
async def transfer_to_human_node(state: CustomerServiceState) -> CustomerServiceState:
    """
    è½¬æ¥äººå·¥å®¢æœ
    """
    session_id = state["session_id"]

    # é€šçŸ¥äººå·¥å®¢æœç³»ç»Ÿ
    await notify_human_agent({
        "session_id": session_id,
        "reason": state.get("human_reason", "ç”¨æˆ·ä¸»åŠ¨è¯·æ±‚"),
        "context": state["messages"][-5:]  # æœ€è¿‘5æ¡æ¶ˆæ¯
    })

    state["final_response"] = "æ­£åœ¨ä¸ºæ‚¨è½¬æ¥äººå·¥å®¢æœï¼Œè¯·ç¨å€™..."
    state["next_step"] = "end"

    return state
```

### 3.3 å®Œæ•´çš„Graphå®šä¹‰

```python
from langgraph.graph import StateGraph, END

def create_customer_service_graph():
    """åˆ›å»ºå®¢æœæœºå™¨äººçŠ¶æ€å›¾"""

    workflow = StateGraph(CustomerServiceState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("intent_recognition", intent_recognition_node)
    workflow.add_node("router", router_node)
    workflow.add_node("greeting_handler", greeting_handler_node)
    workflow.add_node("knowledge_retrieval", knowledge_retrieval_node)
    workflow.add_node("order_tool", order_tool_node)
    workflow.add_node("after_sales_handler", after_sales_handler_node)
    workflow.add_node("complaint_handler", complaint_handler_node)
    workflow.add_node("chitchat_handler", chitchat_handler_node)
    workflow.add_node("response_generation", response_generation_node)
    workflow.add_node("transfer_to_human", transfer_to_human_node)
    workflow.add_node("fallback_handler", fallback_handler_node)

    # è®¾ç½®å…¥å£
    workflow.set_entry_point("intent_recognition")

    # æ·»åŠ è¾¹
    workflow.add_edge("intent_recognition", "router")

    # æ¡ä»¶è·¯ç”±è¾¹
    workflow.add_conditional_edges(
        "router",
        lambda x: x["next_step"],
        {
            "greeting_handler": "greeting_handler",
            "knowledge_retrieval": "knowledge_retrieval",
            "order_tool": "order_tool",
            "after_sales_handler": "after_sales_handler",
            "complaint_handler": "complaint_handler",
            "chitchat_handler": "chitchat_handler",
            "transfer_to_human": "transfer_to_human",
            "fallback_handler": "fallback_handler"
        }
    )

    # å¤„ç†ååˆ°å“åº”ç”Ÿæˆ
    workflow.add_edge("greeting_handler", "response_generation")
    workflow.add_edge("knowledge_retrieval", "response_generation")
    workflow.add_edge("order_tool", "response_generation")
    workflow.add_edge("after_sales_handler", "response_generation")
    workflow.add_edge("complaint_handler", "response_generation")
    workflow.add_edge("chitchat_handler", "response_generation")
    workflow.add_edge("fallback_handler", "response_generation")

    # ç»“æŸèŠ‚ç‚¹
    workflow.add_edge("response_generation", END)
    workflow.add_edge("transfer_to_human", END)

    # ç¼–è¯‘
    app = workflow.compile()

    return app
```

---

## å››ã€æ ¸å¿ƒåŠŸèƒ½æ¨¡å—è¯¦ç»†è®¾è®¡

### 4.1 çŸ¥è¯†åº“RAGç³»ç»Ÿ

#### çŸ¥è¯†åº“ç»“æ„è®¾è®¡
```python
# æ–‡æ¡£ç»“æ„
class KnowledgeDocument:
    id: str
    title: str
    content: str
    category: str  # äº§å“/æ”¿ç­–/FAQ/æ“ä½œæŒ‡å—
    tags: List[str]
    metadata: dict
    embedding: List[float]
    create_time: datetime
    update_time: datetime
```

#### RAGå®ç°
```python
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import PGVector
from langchain_openai import OpenAIEmbeddings

class RAGKnowledgeBase:
    def __init__(self):
        self.embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50
        )
        self.vectorstore = PGVector(
            connection_string="postgresql://user:pass@localhost:5432/db",
            embedding_function=self.embeddings
        )

    async def add_documents(self, documents: List[str], metadata: List[dict]):
        """æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
        chunks = self.text_splitter.create_documents(documents, metadata)
        await self.vectorstore.aadd_documents(chunks)

    async def retrieve(self, query: str, k: int = 5, filter: dict = None):
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        results = await self.vectorstore.asimilarity_search_with_score(
            query=query,
            k=k,
            filter=filter
        )
        return results

    async def hybrid_search(self, query: str, k: int = 5):
        """æ··åˆæœç´¢(å‘é‡+å…³é”®è¯)"""
        # å‘é‡æœç´¢
        vector_results = await self.retrieve(query, k)

        # å…³é”®è¯æœç´¢(ä½¿ç”¨PostgreSQLå…¨æ–‡æ£€ç´¢)
        keyword_results = await self.keyword_search(query, k)

        # ç»“æœèåˆå’Œé‡æ’åº
        merged = self.merge_and_rerank(vector_results, keyword_results)
        return merged[:k]
```

### 4.2 å¯¹è¯çŠ¶æ€ç®¡ç†

```python
from datetime import datetime, timedelta
import redis
import json

class SessionManager:
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client
        self.session_ttl = 3600 * 2  # 2å°æ—¶è¿‡æœŸ

    async def create_session(self, user_id: str) -> str:
        """åˆ›å»ºæ–°ä¼šè¯"""
        session_id = f"session:{user_id}:{datetime.now().timestamp()}"
        session_data = {
            "user_id": user_id,
            "created_at": datetime.now().isoformat(),
            "messages": [],
            "context": {}
        }
        await self.redis.setex(
            session_id,
            self.session_ttl,
            json.dumps(session_data)
        )
        return session_id

    async def get_session(self, session_id: str) -> dict:
        """è·å–ä¼šè¯æ•°æ®"""
        data = await self.redis.get(session_id)
        return json.loads(data) if data else None

    async def update_session(self, session_id: str, data: dict):
        """æ›´æ–°ä¼šè¯"""
        await self.redis.setex(
            session_id,
            self.session_ttl,
            json.dumps(data)
        )

    async def add_message(self, session_id: str, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°ä¼šè¯"""
        session = await self.get_session(session_id)
        if session:
            session["messages"].append({
                "role": role,
                "content": content,
                "timestamp": datetime.now().isoformat()
            })
            await self.update_session(session_id, session)
```

### 4.3 å·¥å…·è°ƒç”¨ç³»ç»Ÿ

```python
from langchain.tools import BaseTool
from pydantic import BaseModel, Field

class OrderQueryInput(BaseModel):
    order_id: str = Field(description="è®¢å•å·")

class OrderQueryTool(BaseTool):
    name = "order_query"
    description = "æŸ¥è¯¢è®¢å•ä¿¡æ¯ï¼Œéœ€è¦æä¾›è®¢å•å·"
    args_schema = OrderQueryInput

    async def _arun(self, order_id: str) -> dict:
        """å¼‚æ­¥æ‰§è¡Œ"""
        # è°ƒç”¨è®¢å•ç³»ç»ŸAPI
        order_info = await self.query_order_from_db(order_id)
        return {
            "order_id": order_id,
            "status": order_info["status"],
            "products": order_info["products"],
            "total_amount": order_info["total_amount"],
            "create_time": order_info["create_time"]
        }

    async def query_order_from_db(self, order_id: str):
        """ä»æ•°æ®åº“æŸ¥è¯¢è®¢å•"""
        # å®ç°æ•°æ®åº“æŸ¥è¯¢é€»è¾‘
        pass

# å…¶ä»–å·¥å…·
class RefundTool(BaseTool):
    name = "refund_application"
    description = "ç”³è¯·é€€æ¬¾"
    # ...

class LogisticsTool(BaseTool):
    name = "logistics_query"
    description = "æŸ¥è¯¢ç‰©æµä¿¡æ¯"
    # ...

# å·¥å…·é›†åˆ
tools = [
    OrderQueryTool(),
    RefundTool(),
    LogisticsTool()
]
```

### 4.4 äººå·¥è½¬æ¥ç³»ç»Ÿ

```python
from enum import Enum
from typing import Optional

class AgentStatus(Enum):
    AVAILABLE = "available"
    BUSY = "busy"
    OFFLINE = "offline"

class HumanAgentPool:
    def __init__(self):
        self.agents = {}  # agent_id -> agent_info
        self.queue = []   # ç­‰å¾…é˜Ÿåˆ—

    def add_agent(self, agent_id: str, skills: List[str]):
        """æ·»åŠ äººå·¥å®¢æœ"""
        self.agents[agent_id] = {
            "id": agent_id,
            "status": AgentStatus.AVAILABLE,
            "skills": skills,
            "current_sessions": [],
            "max_sessions": 5
        }

    def find_available_agent(self, required_skills: List[str] = None) -> Optional[str]:
        """æŸ¥æ‰¾å¯ç”¨å®¢æœ"""
        for agent_id, agent in self.agents.items():
            if agent["status"] == AgentStatus.AVAILABLE:
                if len(agent["current_sessions"]) < agent["max_sessions"]:
                    if not required_skills or any(s in agent["skills"] for s in required_skills):
                        return agent_id
        return None

    async def transfer_to_agent(self, session_id: str, context: dict):
        """è½¬æ¥åˆ°äººå·¥"""
        agent_id = self.find_available_agent()

        if agent_id:
            # åˆ†é…ç»™å®¢æœ
            self.agents[agent_id]["current_sessions"].append(session_id)
            await self.notify_agent(agent_id, session_id, context)
            return {"success": True, "agent_id": agent_id}
        else:
            # åŠ å…¥ç­‰å¾…é˜Ÿåˆ—
            self.queue.append({
                "session_id": session_id,
                "context": context,
                "timestamp": datetime.now()
            })
            return {"success": False, "message": "æ‰€æœ‰å®¢æœå¿™ç¢Œï¼Œå·²åŠ å…¥ç­‰å¾…é˜Ÿåˆ—"}
```

---

## äº”ã€æ•°æ®åº“è®¾è®¡

### 5.1 PostgreSQLè¡¨ç»“æ„

```sql
-- ç”¨æˆ·è¡¨
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    user_id VARCHAR(100) UNIQUE NOT NULL,
    username VARCHAR(100),
    phone VARCHAR(20),
    email VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ä¼šè¯è¡¨
CREATE TABLE sessions (
    id SERIAL PRIMARY KEY,
    session_id VARCHAR(200) UNIQUE NOT NULL,
    user_id VARCHAR(100) REFERENCES users(user_id),
    start_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    end_time TIMESTAMP,
    status VARCHAR(20), -- active, ended, transferred
    assigned_agent_id VARCHAR(100),
    satisfaction_score INT
);

-- æ¶ˆæ¯è¡¨
CREATE TABLE messages (
    id SERIAL PRIMARY KEY,
    session_id VARCHAR(200) REFERENCES sessions(session_id),
    role VARCHAR(20), -- user, assistant, system
    content TEXT,
    intent VARCHAR(50),
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    metadata JSONB
);

-- çŸ¥è¯†åº“è¡¨
CREATE TABLE knowledge_base (
    id SERIAL PRIMARY KEY,
    title VARCHAR(500),
    content TEXT,
    category VARCHAR(100),
    tags TEXT[],
    embedding vector(1536), -- ä½¿ç”¨pgvectoræ‰©å±•
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- åˆ›å»ºå‘é‡ç´¢å¼•
CREATE INDEX ON knowledge_base USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);

-- å·¥å•è¡¨
CREATE TABLE tickets (
    id SERIAL PRIMARY KEY,
    ticket_id VARCHAR(100) UNIQUE NOT NULL,
    session_id VARCHAR(200),
    user_id VARCHAR(100),
    category VARCHAR(50), -- æŠ•è¯‰/å»ºè®®/å’¨è¯¢
    priority VARCHAR(20), -- high/medium/low
    status VARCHAR(20), -- open/in_progress/resolved/closed
    description TEXT,
    assigned_to VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    resolved_at TIMESTAMP
);

-- äººå·¥å®¢æœè¡¨
CREATE TABLE agents (
    id SERIAL PRIMARY KEY,
    agent_id VARCHAR(100) UNIQUE NOT NULL,
    name VARCHAR(100),
    skills TEXT[],
    status VARCHAR(20), -- available/busy/offline
    max_concurrent_sessions INT DEFAULT 5,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- åé¦ˆè¡¨
CREATE TABLE feedback (
    id SERIAL PRIMARY KEY,
    session_id VARCHAR(200),
    user_id VARCHAR(100),
    rating INT, -- 1-5
    comment TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

---

## å…­ã€APIæ¥å£è®¾è®¡

### 6.1 RESTful API

```python
from fastapi import FastAPI, WebSocket, HTTPException
from pydantic import BaseModel
from typing import List, Optional

app = FastAPI(title="å®¢æœæœºå™¨äººAPI")

# è¯·æ±‚æ¨¡å‹
class ChatRequest(BaseModel):
    session_id: Optional[str] = None
    user_id: str
    message: str
    metadata: Optional[dict] = {}

class ChatResponse(BaseModel):
    session_id: str
    message: str
    intent: str
    suggestions: List[str] = []
    need_human: bool = False

# æ¥å£
@app.post("/api/v1/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    èŠå¤©æ¥å£
    """
    # è·å–æˆ–åˆ›å»ºä¼šè¯
    if not request.session_id:
        session_id = await session_manager.create_session(request.user_id)
    else:
        session_id = request.session_id

    # æ‰§è¡ŒLangGraphå·¥ä½œæµ
    graph = create_customer_service_graph()

    initial_state = {
        "messages": [HumanMessage(content=request.message)],
        "session_id": session_id,
        "user_id": request.user_id,
        "loop_count": 0
    }

    result = await graph.ainvoke(initial_state)

    return ChatResponse(
        session_id=session_id,
        message=result["final_response"],
        intent=result["intent"],
        need_human=result.get("need_human", False)
    )

@app.post("/api/v1/sessions/{session_id}/transfer")
async def transfer_to_human(session_id: str):
    """
    è½¬äººå·¥æ¥å£
    """
    session = await session_manager.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, message="ä¼šè¯ä¸å­˜åœ¨")

    result = await human_agent_pool.transfer_to_agent(
        session_id,
        context=session["messages"][-10:]
    )

    return result

@app.get("/api/v1/sessions/{session_id}/history")
async def get_chat_history(session_id: str):
    """
    è·å–èŠå¤©å†å²
    """
    session = await session_manager.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, message="ä¼šè¯ä¸å­˜åœ¨")

    return {"messages": session["messages"]}

@app.post("/api/v1/knowledge/add")
async def add_knowledge(
    title: str,
    content: str,
    category: str,
    tags: List[str]
):
    """
    æ·»åŠ çŸ¥è¯†åº“æ–‡æ¡£
    """
    await knowledge_base.add_documents(
        [content],
        [{"title": title, "category": category, "tags": tags}]
    )
    return {"success": True}

@app.post("/api/v1/feedback")
async def submit_feedback(
    session_id: str,
    rating: int,
    comment: Optional[str] = None
):
    """
    æäº¤åé¦ˆ
    """
    await save_feedback(session_id, rating, comment)
    return {"success": True}
```

### 6.2 WebSocketå®æ—¶é€šä¿¡

```python
@app.websocket("/ws/chat/{session_id}")
async def websocket_chat(websocket: WebSocket, session_id: str):
    """
    WebSocketå®æ—¶èŠå¤©
    """
    await websocket.accept()

    try:
        while True:
            # æ¥æ”¶æ¶ˆæ¯
            data = await websocket.receive_json()
            message = data["message"]

            # å¤„ç†æ¶ˆæ¯
            graph = create_customer_service_graph()
            initial_state = {
                "messages": [HumanMessage(content=message)],
                "session_id": session_id,
                "user_id": data.get("user_id"),
                "loop_count": 0
            }

            # æµå¼è¾“å‡º
            async for event in graph.astream(initial_state):
                await websocket.send_json({
                    "type": "chunk",
                    "data": event
                })

            # å‘é€å®Œæˆ
            await websocket.send_json({
                "type": "complete"
            })

    except Exception as e:
        await websocket.close()
```

---

## ä¸ƒã€å‰ç«¯ç•Œé¢è®¾è®¡

### 7.1 Reactç»„ä»¶ç»“æ„

```typescript
// src/components/ChatInterface.tsx
import React, { useState, useEffect, useRef } from 'react';
import { message as antdMessage } from 'antd';

interface Message {
  role: 'user' | 'assistant';
  content: string;
  timestamp: string;
}

const ChatInterface: React.FC = () => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [input, setInput] = useState('');
  const [sessionId, setSessionId] = useState<string | null>(null);
  const [loading, setLoading] = useState(false);
  const wsRef = useRef<WebSocket | null>(null);

  useEffect(() => {
    // å»ºç«‹WebSocketè¿æ¥
    connectWebSocket();
    return () => {
      wsRef.current?.close();
    };
  }, []);

  const connectWebSocket = () => {
    const ws = new WebSocket(`ws://localhost:8000/ws/chat/${sessionId || 'new'}`);

    ws.onmessage = (event) => {
      const data = JSON.parse(event.data);
      if (data.type === 'chunk') {
        // å¤„ç†æµå¼å“åº”
        updateLastMessage(data.data);
      } else if (data.type === 'complete') {
        setLoading(false);
      }
    };

    wsRef.current = ws;
  };

  const sendMessage = async () => {
    if (!input.trim()) return;

    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    const userMessage: Message = {
      role: 'user',
      content: input,
      timestamp: new Date().toISOString()
    };
    setMessages(prev => [...prev, userMessage]);
    setInput('');
    setLoading(true);

    // å‘é€åˆ°æœåŠ¡å™¨
    wsRef.current?.send(JSON.stringify({
      message: input,
      user_id: 'user123'
    }));
  };

  const requestHumanAgent = async () => {
    try {
      const response = await fetch(`/api/v1/sessions/${sessionId}/transfer`, {
        method: 'POST'
      });
      const data = await response.json();
      antdMessage.success('æ­£åœ¨ä¸ºæ‚¨è½¬æ¥äººå·¥å®¢æœ...');
    } catch (error) {
      antdMessage.error('è½¬æ¥å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•');
    }
  };

  return (
    <div className="chat-container">
      <div className="chat-header">
        <h2>æ™ºèƒ½å®¢æœ</h2>
        <button onClick={requestHumanAgent}>è½¬äººå·¥</button>
      </div>

      <div className="chat-messages">
        {messages.map((msg, idx) => (
          <div key={idx} className={`message ${msg.role}`}>
            <div className="message-content">{msg.content}</div>
            <div className="message-time">{new Date(msg.timestamp).toLocaleTimeString()}</div>
          </div>
        ))}
        {loading && <div className="loading">æ­£åœ¨è¾“å…¥ä¸­...</div>}
      </div>

      <div className="chat-input">
        <input
          type="text"
          value={input}
          onChange={(e) => setInput(e.target.value)}
          onKeyPress={(e) => e.key === 'Enter' && sendMessage()}
          placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."
        />
        <button onClick={sendMessage}>å‘é€</button>
      </div>
    </div>
  );
};

export default ChatInterface;
```

---

## å…«ã€éƒ¨ç½²æ–¹æ¡ˆ

### 8.1 Docker Composeé…ç½®

```yaml
# docker-compose.yml
version: '3.8'

services:
  # APIæœåŠ¡
  api:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/customerservice
      - REDIS_URL=redis://redis:6379
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      - postgres
      - redis
    volumes:
      - ./backend:/app
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload

  # å‰ç«¯æœåŠ¡
  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    environment:
      - REACT_APP_API_URL=http://localhost:8000

  # PostgreSQLæ•°æ®åº“
  postgres:
    image: pgvector/pgvector:pg16
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=customerservice
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  # Redisç¼“å­˜
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  # Nginxåå‘ä»£ç†
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - api
      - frontend

  # ç›‘æ§ - Prometheus
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus

  # ç›‘æ§ - Grafana
  grafana:
    image: grafana/grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:
```

### 8.2 Kuberneteséƒ¨ç½²(å¯é€‰)

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: customerservice-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: customerservice-api
  template:
    metadata:
      labels:
        app: customerservice-api
    spec:
      containers:
      - name: api
        image: customerservice-api:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: openai-secret
              key: api-key
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
---
apiVersion: v1
kind: Service
metadata:
  name: customerservice-api-service
spec:
  selector:
    app: customerservice-api
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: LoadBalancer
```

---

## ä¹ã€ç›‘æ§ä¸æ—¥å¿—

### 9.1 æ—¥å¿—ç³»ç»Ÿ

```python
import logging
from datetime import datetime
import json

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'logs/app_{datetime.now().strftime("%Y%m%d")}.log'),
        logging.StreamHandler()
    ]
)

class ChatLogger:
    def __init__(self):
        self.logger = logging.getLogger('customerservice')

    def log_conversation(self, session_id: str, user_msg: str, bot_msg: str, intent: str):
        """è®°å½•å¯¹è¯"""
        self.logger.info(json.dumps({
            "type": "conversation",
            "session_id": session_id,
            "user_message": user_msg,
            "bot_response": bot_msg,
            "intent": intent,
            "timestamp": datetime.now().isoformat()
        }, ensure_ascii=False))

    def log_error(self, session_id: str, error: Exception):
        """è®°å½•é”™è¯¯"""
        self.logger.error(json.dumps({
            "type": "error",
            "session_id": session_id,
            "error": str(error),
            "timestamp": datetime.now().isoformat()
        }, ensure_ascii=False))

    def log_transfer(self, session_id: str, reason: str):
        """è®°å½•è½¬äººå·¥"""
        self.logger.info(json.dumps({
            "type": "transfer",
            "session_id": session_id,
            "reason": reason,
            "timestamp": datetime.now().isoformat()
        }, ensure_ascii=False))
```

### 9.2 æ€§èƒ½ç›‘æ§

```python
from prometheus_client import Counter, Histogram, Gauge
import time

# å®šä¹‰æŒ‡æ ‡
conversation_counter = Counter('conversations_total', 'æ€»å¯¹è¯æ•°')
intent_counter = Counter('intents_total', 'æ„å›¾åˆ†ç±»ç»Ÿè®¡', ['intent'])
response_time = Histogram('response_time_seconds', 'å“åº”æ—¶é—´')
active_sessions = Gauge('active_sessions', 'æ´»è·ƒä¼šè¯æ•°')
transfer_rate = Gauge('human_transfer_rate', 'äººå·¥è½¬æ¥ç‡')

class MetricsCollector:
    @staticmethod
    def record_conversation():
        conversation_counter.inc()

    @staticmethod
    def record_intent(intent: str):
        intent_counter.labels(intent=intent).inc()

    @staticmethod
    def measure_response_time(func):
        """è£…é¥°å™¨ï¼šæµ‹é‡å“åº”æ—¶é—´"""
        async def wrapper(*args, **kwargs):
            start = time.time()
            result = await func(*args, **kwargs)
            duration = time.time() - start
            response_time.observe(duration)
            return result
        return wrapper
```

---

## åã€å®æ–½æ­¥éª¤

### ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€æ­å»º (1-2å‘¨)
1. âœ… æ­å»ºå¼€å‘ç¯å¢ƒ
2. âœ… åˆ›å»ºé¡¹ç›®ç»“æ„
3. âœ… é…ç½®æ•°æ®åº“å’ŒRedis
4. âœ… å®ç°åŸºç¡€APIæ¡†æ¶
5. âœ… å®Œæˆç®€å•çš„æ„å›¾è¯†åˆ«

### ç¬¬äºŒé˜¶æ®µï¼šæ ¸å¿ƒåŠŸèƒ½ (2-3å‘¨)
1. âœ… å®ç°LangGraphçŠ¶æ€æœº
2. âœ… å¼€å‘çŸ¥è¯†åº“RAGç³»ç»Ÿ
3. âœ… é›†æˆLLMæœåŠ¡
4. âœ… å®ç°å¤šè½®å¯¹è¯ç®¡ç†
5. âœ… å¼€å‘å·¥å…·è°ƒç”¨ç³»ç»Ÿ

### ç¬¬ä¸‰é˜¶æ®µï¼šé«˜çº§åŠŸèƒ½ (2-3å‘¨)
1. âœ… å®ç°äººå·¥è½¬æ¥ç³»ç»Ÿ
2. âœ… å¼€å‘å‰ç«¯ç•Œé¢
3. âœ… æ·»åŠ WebSocketå®æ—¶é€šä¿¡
4. âœ… å®ç°ä¼šè¯ç®¡ç†
5. âœ… æ·»åŠ æ—¥å¿—å’Œç›‘æ§

### ç¬¬å››é˜¶æ®µï¼šæµ‹è¯•ä¼˜åŒ– (1-2å‘¨)
1. âœ… å•å…ƒæµ‹è¯•
2. âœ… é›†æˆæµ‹è¯•
3. âœ… æ€§èƒ½æµ‹è¯•å’Œä¼˜åŒ–
4. âœ… å®‰å…¨æµ‹è¯•
5. âœ… ç”¨æˆ·ä½“éªŒä¼˜åŒ–

### ç¬¬äº”é˜¶æ®µï¼šä¸Šçº¿éƒ¨ç½² (1å‘¨)
1. âœ… å®¹å™¨åŒ–æ‰“åŒ…
2. âœ… éƒ¨ç½²åˆ°æµ‹è¯•ç¯å¢ƒ
3. âœ… å‹åŠ›æµ‹è¯•
4. âœ… éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
5. âœ… ç›‘æ§å’Œç»´æŠ¤

---

## åä¸€ã€å…³é”®ä»£ç ç¤ºä¾‹

### 11.1 å®Œæ•´çš„main.py

```python
# backend/main.py
from fastapi import FastAPI, WebSocket, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import uvicorn

from graph import create_customer_service_graph
from models import ChatRequest, ChatResponse
from session_manager import SessionManager
from knowledge_base import RAGKnowledgeBase
from human_agent import HumanAgentPool
from logger import ChatLogger
from metrics import MetricsCollector

# å…¨å±€å˜é‡
session_manager: SessionManager = None
knowledge_base: RAGKnowledgeBase = None
human_agent_pool: HumanAgentPool = None
chat_logger: ChatLogger = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    global session_manager, knowledge_base, human_agent_pool, chat_logger

    session_manager = SessionManager()
    knowledge_base = RAGKnowledgeBase()
    human_agent_pool = HumanAgentPool()
    chat_logger = ChatLogger()

    yield

    # å…³é—­æ—¶æ¸…ç†
    pass

app = FastAPI(
    title="æ™ºèƒ½å®¢æœæœºå™¨äººAPI",
    version="1.0.0",
    lifespan=lifespan
)

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {"message": "æ™ºèƒ½å®¢æœæœºå™¨äººAPI", "version": "1.0.0"}

@app.get("/health")
async def health_check():
    return {"status": "healthy"}

# ... (å‰é¢å®šä¹‰çš„APIæ¥å£)

if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True
    )
```

### 11.2 requirements.txt

```
# æ ¸å¿ƒæ¡†æ¶
fastapi==0.104.1
uvicorn[standard]==0.24.0
python-multipart==0.0.6

# LangChainç”Ÿæ€
langchain==0.1.0
langgraph==0.0.20
langchain-openai==0.0.2
langchain-community==0.0.10

# æ•°æ®åº“
psycopg2-binary==2.9.9
pgvector==0.2.3
redis==5.0.1
sqlalchemy==2.0.23

# å‘é‡å­˜å‚¨
chromadb==0.4.18
# qdrant-client==1.7.0  # å¯é€‰

# OpenAI
openai==1.6.1

# å·¥å…·å’Œå®ç”¨åº“
pydantic==2.5.2
python-dotenv==1.0.0
httpx==0.25.2

# ç›‘æ§
prometheus-client==0.19.0

# æ—¥å¿—
python-json-logger==2.0.7

# WebSocket
websockets==12.0

# æµ‹è¯•
pytest==7.4.3
pytest-asyncio==0.21.1
```

---

## åäºŒã€æœ€ä½³å®è·µä¸æ³¨æ„äº‹é¡¹

### 12.1 æ€§èƒ½ä¼˜åŒ–
- âœ… ä½¿ç”¨Redisç¼“å­˜é¢‘ç¹æŸ¥è¯¢çš„æ•°æ®
- âœ… å‘é‡æ£€ç´¢ç»“æœç¼“å­˜
- âœ… ä½¿ç”¨å¼‚æ­¥IOæå‡å¹¶å‘æ€§èƒ½
- âœ… æ‰¹é‡å¤„ç†çŸ¥è¯†åº“æ›´æ–°
- âœ… ä½¿ç”¨è¿æ¥æ± ç®¡ç†æ•°æ®åº“è¿æ¥

### 12.2 å®‰å…¨æ€§
- âœ… APIæ¥å£æ·»åŠ è®¤è¯å’Œæˆæƒ
- âœ… æ•æ„Ÿä¿¡æ¯åŠ å¯†å­˜å‚¨
- âœ… é˜²æ­¢SQLæ³¨å…¥å’ŒXSSæ”»å‡»
- âœ… é™æµå’Œé˜²DDoS
- âœ… æ—¥å¿—è„±æ•å¤„ç†

### 12.3 å¯æ‰©å±•æ€§
- âœ… ä½¿ç”¨æ¶ˆæ¯é˜Ÿåˆ—è§£è€¦ç³»ç»Ÿ
- âœ… å¾®æœåŠ¡æ¶æ„è®¾è®¡
- âœ… æ°´å¹³æ‰©å±•APIæœåŠ¡
- âœ… åˆ†ç‰‡å­˜å‚¨å¤§è§„æ¨¡æ•°æ®
- âœ… ä½¿ç”¨CDNåŠ é€Ÿé™æ€èµ„æº

### 12.4 ç”¨æˆ·ä½“éªŒ
- âœ… å“åº”æ—¶é—´<2ç§’
- âœ… æµå¼è¾“å‡ºæå‡æ„ŸçŸ¥é€Ÿåº¦
- âœ… æä¾›å¿«æ·å›å¤é€‰é¡¹
- âœ… æ”¯æŒå¤šåª’ä½“æ¶ˆæ¯
- âœ… ç§»åŠ¨ç«¯é€‚é…

### 12.5 è¿ç»´ç›‘æ§
- âœ… å®æ—¶ç›‘æ§ç³»ç»Ÿå¥åº·åº¦
- âœ… æ—¥å¿—é›†ä¸­ç®¡ç†å’Œåˆ†æ
- âœ… å¼‚å¸¸å‘Šè­¦æœºåˆ¶
- âœ… å®šæœŸå¤‡ä»½æ•°æ®
- âœ… ç°åº¦å‘å¸ƒç­–ç•¥

---

## åä¸‰ã€æœªæ¥æ‰©å±•æ–¹å‘

### 13.1 åŠŸèƒ½æ‰©å±•
- ğŸ”® å¤šè¯­è¨€æ”¯æŒ
- ğŸ”® è¯­éŸ³äº¤äº’(ASR + TTS)
- ğŸ”® å›¾åƒè¯†åˆ«(å•†å“è¯†åˆ«ã€å‡­è¯è¯†åˆ«)
- ğŸ”® æƒ…æ„Ÿåˆ†æ
- ğŸ”® ä¸»åŠ¨æ¨é€(ä¿ƒé”€ã€æé†’)
- ğŸ”® ä¸ªæ€§åŒ–æ¨è

### 13.2 æŠ€æœ¯å‡çº§
- ğŸ”® å¾®è°ƒä¸“å±é¢†åŸŸæ¨¡å‹
- ğŸ”® å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å¯¹è¯ç­–ç•¥
- ğŸ”® å¤šæ¨¡æ€å¤§æ¨¡å‹é›†æˆ
- ğŸ”® çŸ¥è¯†å›¾è°±å¢å¼º
- ğŸ”® è”é‚¦å­¦ä¹ ä¿æŠ¤éšç§

---

## åå››ã€æ€»ç»“

æœ¬æ–¹æ¡ˆæä¾›äº†ä¸€ä¸ªå®Œæ•´çš„ã€å¯å®ç°çš„åŸºäºLangGraphçš„æ™ºèƒ½å®¢æœæœºå™¨äººç³»ç»Ÿè®¾è®¡ã€‚ä¸»è¦ç‰¹ç‚¹ï¼š

âœ… **å®Œæ•´æ€§**: è¦†ç›–ä»æ¶æ„è®¾è®¡åˆ°éƒ¨ç½²è¿ç»´çš„å…¨æµç¨‹
âœ… **å¯å®ç°æ€§**: åŸºäºæˆç†Ÿçš„æŠ€æœ¯æ ˆï¼Œä»£ç å¯ç›´æ¥è¿è¡Œ
âœ… **å¯æ‰©å±•æ€§**: æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•æ–°åŠŸèƒ½
âœ… **ç”Ÿäº§å°±ç»ª**: åŒ…å«ç›‘æ§ã€æ—¥å¿—ã€å®‰å…¨ç­‰ç”Ÿäº§ç¯å¢ƒå¿…å¤‡åŠŸèƒ½

### å¿«é€Ÿå¯åŠ¨å‘½ä»¤
```bash
# 1. å…‹éš†é¡¹ç›®
git clone <your-repo>
cd customerservice-bot

# 2. é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘.envæ–‡ä»¶ï¼Œå¡«å…¥OPENAI_API_KEYç­‰é…ç½®

# 3. å¯åŠ¨æœåŠ¡
docker-compose up -d

# 4. åˆå§‹åŒ–æ•°æ®åº“
docker-compose exec api python scripts/init_db.py

# 5. å¯¼å…¥çŸ¥è¯†åº“
docker-compose exec api python scripts/import_knowledge.py

# 6. è®¿é—®
# APIæ–‡æ¡£: http://localhost:8000/docs
# å‰ç«¯ç•Œé¢: http://localhost:3000
# Grafanaç›‘æ§: http://localhost:3001
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0
**æœ€åæ›´æ–°**: 2025-12-03
**ä½œè€…**: Claude AI
**è”ç³»æ–¹å¼**: æ ¹æ®å®é™…æƒ…å†µå¡«å†™
